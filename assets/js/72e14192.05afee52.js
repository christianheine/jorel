"use strict";(self.webpackChunkjorel_docs=self.webpackChunkjorel_docs||[]).push([[814],{795:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>i,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"quick-start","title":"Quick Start","description":"Get started with JorEl, a unified interface for multiple LLM providers including OpenAI, Anthropic, Groq, Grok, Google Vertex AI, Mistral and Ollama.","source":"@site/docs/quick-start.md","sourceDirName":".","slug":"/quick-start","permalink":"/jorel/docs/quick-start","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"learn","next":{"title":"Introduction","permalink":"/jorel/docs/intro"}}');var a=t(4848),o=t(8453);const i={sidebar_position:1},r="Quick Start",l={},c=[{value:"Installation",id:"installation",level:2},{value:"Getting started",id:"getting-started",level:2},{value:"Initialize JorEl",id:"initialize-jorel",level:3},{value:"Generating text",id:"generating-text",level:3},{value:"Basic usage",id:"basic-usage",level:4},{value:"Use with configuration",id:"use-with-configuration",level:4},{value:"Use with metadata",id:"use-with-metadata",level:4},{value:"Generating JSON",id:"generating-json",level:3},{value:"Working with Documents",id:"working-with-documents",level:3},{value:"Using Tools",id:"using-tools",level:3},{value:"Streaming with Tools",id:"streaming-with-tools",level:3},{value:"Embeddings",id:"embeddings",level:2},{value:"Preview to agents",id:"preview-to-agents",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",p:"p",pre:"pre",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"quick-start",children:"Quick Start"})}),"\n",(0,a.jsx)(n.p,{children:"Get started with JorEl, a unified interface for multiple LLM providers including OpenAI, Anthropic, Groq, Grok, Google Vertex AI, Mistral and Ollama."}),"\n",(0,a.jsx)(n.h2,{id:"installation",children:"Installation"}),"\n",(0,a.jsx)(n.p,{children:"Install JorEl using npm:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"npm install jorel\n"})}),"\n",(0,a.jsx)(n.p,{children:"Or using yarn:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"yarn add jorel\n"})}),"\n",(0,a.jsx)(n.h2,{id:"getting-started",children:"Getting started"}),"\n",(0,a.jsx)(n.h3,{id:"initialize-jorel",children:"Initialize JorEl"}),"\n",(0,a.jsx)(n.p,{children:"Create a new JorEl instance with your preferred provider(s). Here's an example using OpenAI:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"import {JorEl} from 'jorel';\n\nconst jorEl = new JorEl({\n  openAI: {apiKey: process.env.OPENAI_API_KEY},\n});\n"})}),"\n",(0,a.jsx)(n.p,{children:"You can initialize multiple providers at once:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"const jorEl = new JorEl({\n  openAI: {apiKey: process.env.OPENAI_API_KEY},\n  anthropic: {apiKey: process.env.ANTHROPIC_API_KEY},\n  groq: {apiKey: process.env.GROQ_API_KEY},\n});\n"})}),"\n",(0,a.jsx)(n.p,{children:"Alternatively, you can just pass a boolean per provider and JorEl will use respective environment variables:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"\nconst jorEl = new JorEl({\n  openAI: true,     // Will use OPENAI_API_KEY environment variable\n  anthropic: true,  // Will use ANTHROPIC_API_KEY environment variable\n  groq: true,       // Will use GROQ_API_KEY environment variable\n  grok: true,       // Will use GROK_API_KEY environment variable\n  vertexAI: true,   // Will use GCP_PROJECT, GCP_LOCATION, GOOGLE_APPLICATION_CREDENTIALS environment variables\n  mistral: true,    // Will use MISTRAL_API_KEY environment variable\n  ollama: true     // No environment variables needed\n});\n"})}),"\n",(0,a.jsx)(n.h3,{id:"generating-text",children:"Generating text"}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:"text"})," method is the simplest way to get responses from the LLM:"]}),"\n",(0,a.jsx)(n.h4,{id:"basic-usage",children:"Basic usage"}),"\n",(0,a.jsx)(n.p,{children:"When using the text method without any additional configuration, JorEl will use the default model and provider, and return the response as a string."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'const response = await jorEl.text("What is the capital of France?");\nconsole.log(response);\n// Paris is the capital of France.\n'})}),"\n",(0,a.jsx)(n.h4,{id:"use-with-configuration",children:"Use with configuration"}),"\n",(0,a.jsx)(n.p,{children:"When using the text method with configuration, you can specify the model, temperature, system message, and other parameters. It will still return the response as a string."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'const response = await jorEl.text("What is the capital of France?", {\n  model: "gpt-4",\n  temperature: 0,\n  systemMessage: "Answer concisely",\n});\nconsole.log(response);\n// Paris\n'})}),"\n",(0,a.jsx)(n.h4,{id:"use-with-metadata",children:"Use with metadata"}),"\n",(0,a.jsx)(n.p,{children:"When using the text method with metadata, you can get additional information about the request and response."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'const {response, meta} = await jorEl.text("What is the capital of France?", {\n    model: "gpt-4",\n    systemMessage: "Answer concisely",\n  },\n  true // Include metadata\n);\nconsole.log(meta);\n// {\n//   model: \'gpt-4\',\n//   provider: \'openai\',\n//   durationMs: 730,\n//   inputTokens: 26,\n//   outputTokens: 16,\n// }\n'})}),"\n",(0,a.jsx)(n.h3,{id:"generating-json",children:"Generating JSON"}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:"json"})," method is similar to ",(0,a.jsx)(n.code,{children:"text"})," but ensures the response is formatted as a JSON object:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'// Set a system message that encourages JSON formatting\njorEl.systemMessage = "Format everything as a JSON object. Use snakeCase for attributes.";\n\nconst response = await jorEl.json("Format this: Name = John, Age = 30, City = Sydney");\nconsole.log(response);\n// {\n//   "first_name": "John",\n//   "age": 30,\n//   "city": "Sydney"\n// }\n'})}),"\n",(0,a.jsx)(n.h3,{id:"working-with-documents",children:"Working with Documents"}),"\n",(0,a.jsx)(n.p,{children:"You can provide context documents to inform the LLM's response:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'// Load document from local documentation files\nconst jorElIntro = await LlmDocument.fromFile("../../docs/docs/intro.md");\nconst jorElQuickStart = await LlmDocument.fromFile("../../docs/docs/quick-start.md");\n\n// Generate the response with the documents as context\nconst response = await jorEl.text("Describe the main features of JorEl.", {\n  documents: [jorElIntro, jorElQuickStart],\n  systemMessage: "Be succinct"\n});\n\nconsole.log(response);\n// JorEl is a powerful TypeScript library that provides a unified interface for working with multiple Large Language Models (LLMs).\n'})}),"\n",(0,a.jsx)(n.h3,{id:"using-tools",children:"Using Tools"}),"\n",(0,a.jsx)(n.p,{children:"JorEl makes it very easy to pass tools to the LLM, including schema setup via zod (though you can of course also pass a plain JSON schema)."}),"\n",(0,a.jsx)(n.p,{children:"For many basic agentic use-case, this should be sufficient. For more advanced setups (e.g. with delegation or transfer), you can look into the JorEl.teams methods which allow you to specify agents and\ndelegates."}),"\n",(0,a.jsxs)(n.p,{children:["This works for both the ",(0,a.jsx)(n.code,{children:"text"})," and ",(0,a.jsx)(n.code,{children:"json"})," methods."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'import {z} from "zod";\n\nconst getWeather = async ({city}: { city: string }) => {\n  // Simulate weather lookup\n  return {temperature: 22, conditions: "sunny"};\n};\n\nconst response = await jorEl.text("What\'s the weather in Sydney?", {\n  tools: [{\n    name: "get_weather",\n    description: "Get the current weather for a city",\n    executor: getWeather,\n    params: z.object({\n      city: z.string(),\n    }),\n  }]\n});\n\nconsole.log(response);\n// The weather in Sydney is 22 degrees and sunny.\n'})}),"\n",(0,a.jsx)(n.h3,{id:"streaming-with-tools",children:"Streaming with Tools"}),"\n",(0,a.jsxs)(n.p,{children:["You can use the ",(0,a.jsx)(n.code,{children:"stream"})," method to stream responses while utilizing tools and documents."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'import {z} from "zod";\n\n// Will return a stream of strings\nconst stream = jorEl.stream("What\'s the weather in my city?", {\n  documents: [{\n    title: "Current location",\n    content: "The user is currently in Sydney.",\n  }],\n  tools: [{\n    name: "get_weather",\n    description: "Get the current weather for a city",\n    executor: getWeather,\n    params: z.object({\n      city: z.string(),\n    }),\n  }],\n});\n\nfor await (const chunk of stream) {\n  process.stdout.write(chunk);\n}\n// The weather in Sydney is 22 degrees and sunny.\n'})}),"\n",(0,a.jsx)(n.h2,{id:"embeddings",children:"Embeddings"}),"\n",(0,a.jsx)(n.p,{children:"JorEl also supports creating embeddings. It will use the default embedding model."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'const embedding = await jorEl.embed("What is the capital of France?");\n'})}),"\n",(0,a.jsxs)(n.p,{children:["Similar to the text method, you can pass a configuration object to the ",(0,a.jsx)(n.code,{children:"embed"})," method. It currently only supports the ",(0,a.jsx)(n.code,{children:"model"})," parameter."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'const embedding = await jorEl.embed("What is the capital of France?", {\n  model: "text-embedding-3-small",\n});\n'})}),"\n",(0,a.jsx)(n.h2,{id:"preview-to-agents",children:"Preview to agents"}),"\n",(0,a.jsx)(n.p,{children:"Agents allow you to define more complex interactions with the LLM, including delegation and transfer. Here's a simple example (which would be better solved with tools, but it should give you an idea\non how to set things up):"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'const jorEl = new JorEl({openAI: true, logger: "console", logLevel: "debug"});\n\njorEl.team.addTools([\n  {\n    name: "get_weather",\n    description: "Get the current temperature and conditions for a city",\n    executor: getWeather,\n    params: z.object({city: z.string()}),\n  },\n]);\n\nconst mainAgent = jorEl.team.addAgent({\n  name: "main_agent",\n  description: "Main agent who communicates between user and other agents.",\n  systemMessageTemplate:\n    "You are a helpful assistant. " +\n    "You try to answer the user\'s questions to the best of your ability. " +\n    "If you can\'t, you\'ll ask another agent for help. " +\n    "These agents are available to you: {{delegates}}",\n});\n\nmainAgent.addDelegate({\n  name: "weather_agent",\n  description: "Can provide weather information for a given location.",\n  systemMessageTemplate: "You are a weather agent. " +\n    "You can provide weather information for a given location.",\n  allowedTools: ["get_weather"],\n});\n\nconst task = await jorEl.team.createTask("What is the weather in Sydney?");\n\nconst executedTask = await jorEl.team.executeTask(task, {\n  limits: {\n    maxIterations: 10,\n    maxGenerations: 6,\n    maxDelegations: 2,\n  },\n});\n\nconst {events, stats, tokens} = executedTask.eventsWithStatistics;\n\nconsole.log("\\nEvents:");\nfor (const event of events) {\n  console.log(`- ${event.eventType}: ${event.action}`);\n}\n\nconsole.log("\\nStatistics:");\nconsole.log({stats, tokens});\n\nconsole.log("\\nResult:");\nconsole.log(executedTask.result);\n\n// Events:\n// - generation: Agent main_agent generated assistant_with_tools message based on user message\n// - delegation: Agent main_agent delegated to weather_agent\n// - generation: Agent weather_agent generated assistant_with_tools message based on user message\n// - toolUse: Agent weather_agent used tool get_weather\n// - generation: Agent weather_agent generated assistant message based on assistant_with_tools message\n// - threadChange: Agent weather_agent returned execution to agent main_agent (Main thread)\n// - generation: Agent main_agent generated assistant message based on assistant_with_tools message\n//\n// Statistics:\n// {\n//   stats: { generations: 4, delegations: 1 },\n//   tokens: { \'gpt-4o-mini\': { input: 515, output: 77 } }\n// }\n//\n// Result:\n//   The current weather in Sydney is sunny with a temperature of 20\xb0C.\n'})}),"\n",(0,a.jsx)(n.p,{children:"Tasks, Agents, and Tools are easily serializable."}),"\n",(0,a.jsx)(n.p,{children:"Tasks can either be run to completion (or until a halt condition is met), or they be processed step-by-step."})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>r});var s=t(6540);const a={},o=s.createContext(a);function i(e){const n=s.useContext(o);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);